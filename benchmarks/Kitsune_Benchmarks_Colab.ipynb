{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ef0465",
   "metadata": {},
   "source": [
    "# Kitsune Optimizer Benchmarks\n",
    "\n",
    "**Before running:** Enable GPU in Runtime → Change runtime type → GPU (T4)\n",
    "\n",
    "This notebook runs comprehensive benchmarks comparing baseline PyTorch vs Kitsune optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b619b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Kitsune from PyPI\n",
    "!pip install torch-kitsune matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc38b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import torch\n",
    "import kitsune\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Kitsune: {kitsune.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e418a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository for benchmark scripts\n",
    "!git clone https://github.com/jeeth-kataria/Kitsune_optimization.git\n",
    "%cd Kitsune_optimization/benchmarks/scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022229f3",
   "metadata": {},
   "source": [
    "## 1. MLP Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3480efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 benchmark_mlp.py --runs 5 --iterations 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d202d",
   "metadata": {},
   "source": [
    "## 2. LeNet-5 Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 benchmark_lenet5.py --runs 5 --iterations 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9b3cf",
   "metadata": {},
   "source": [
    "## 3. ResNet-18 Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ff83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 benchmark_resnet18.py --runs 5 --iterations 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02011f77",
   "metadata": {},
   "source": [
    "## 4. Generate Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba605d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 visualize_results.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b037b479",
   "metadata": {},
   "source": [
    "## 5. Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import json\n",
    "\n",
    "# Display charts\n",
    "print(\"\\n=== SPEEDUP COMPARISON ===\")\n",
    "display(Image('../charts/speedup_comparison.png'))\n",
    "\n",
    "print(\"\\n=== MEMORY COMPARISON ===\")\n",
    "display(Image('../charts/memory_comparison.png'))\n",
    "\n",
    "print(\"\\n=== OPTIMIZATION BREAKDOWN ===\")\n",
    "display(Image('../charts/optimization_breakdown.png'))\n",
    "\n",
    "print(\"\\n=== RESULTS TABLE ===\")\n",
    "display(Image('../charts/results_table.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ecd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print JSON results summary\n",
    "import json\n",
    "\n",
    "for model_file in ['mlp_results.json', 'lenet5_results.json', 'resnet18_results.json']:\n",
    "    with open(f'../results/{model_file}') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{data['model']} RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"GPU: {data['hardware']['gpu']}\")\n",
    "    print(f\"\\nBaseline:     {data['baseline']['mean_time_ms']:.2f}ms ± {data['baseline']['std_time_ms']:.2f}ms\")\n",
    "    print(f\"Kitsune:      {data['kitsune']['mean_time_ms']:.2f}ms ± {data['kitsune']['std_time_ms']:.2f}ms\")\n",
    "    print(f\"Speedup:      {data['improvement']['speedup']:.2f}x\")\n",
    "    print(f\"\\nBaseline Mem: {data['baseline']['peak_memory_mb']:.1f} MB\")\n",
    "    print(f\"Kitsune Mem:  {data['kitsune']['peak_memory_mb']:.1f} MB\")\n",
    "    print(f\"Memory Saved: {data['improvement']['memory_reduction_percent']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99ff54f",
   "metadata": {},
   "source": [
    "## 6. Download Results\n",
    "\n",
    "Download the results and charts to share:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file with all results\n",
    "!zip -r benchmark_results.zip ../results ../charts\n",
    "print(\"\\n✅ Results packaged! Download 'benchmark_results.zip' from the Files panel (left sidebar)\")\n",
    "print(\"\\nOr download individual files:\")\n",
    "print(\"  - ../results/mlp_results.json\")\n",
    "print(\"  - ../results/lenet5_results.json\")\n",
    "print(\"  - ../results/resnet18_results.json\")\n",
    "print(\"  - ../charts/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ef461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download via Colab\n",
    "from google.colab import files\n",
    "files.download('benchmark_results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd1f26",
   "metadata": {},
   "source": [
    "## 7. Share Results\n",
    "\n",
    "Copy the JSON output above and share it, or download the zip file and extract:\n",
    "- `results/*.json` - Raw benchmark data\n",
    "- `charts/*.png` - Visualization charts\n",
    "\n",
    "You can then commit these to your GitHub repository!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
